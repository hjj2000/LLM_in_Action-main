# 幻觉 {#sec-hallucination}

如其他技术一样，即便当前 LLM 在各个领域中有着惊人的表现，但是 LLM 也存在着缺陷和局限。而 “幻觉（Hallucination）”就是一种非常常见的缺陷。

:::{.callout-note title="幻觉"}
**幻觉**是自然语言生成领域的一个术语，是指模型生成了看似合理但实际上并不存在的内容。这些内容可能包含虚构的信息、存在前后矛盾的逻辑、甚至是毫无意义的内容。

**幻觉**原本是心理学领域的专有名词，用于描述一种特殊类型的知觉体验——在没有外部刺激的情况下，清醒的个体的虚假感觉。

**幻觉**是一种不真实的、却又非分真实的虚幻感知。模型容易生成流畅但缺乏真实性的内容，这种现象与心理学中的**幻觉**极为相似，因此在 LLM 领域，我们把 LLM 的这种缺陷称之为 **幻觉**。
:::

幻觉会严重影响依赖 LLM 的下游业务的表现，导致这些业务在真实场景中无法满足用户需求。大语言模型生成内容的真实性是生成式模型接下来面临的重要科学问题之一。

幻觉分为两类：

* 内在幻觉（Intrinsic Hallucinations）：生成的内容与输入的源信息冲突。

    ![内在幻觉的例子](./images/obtuse_angle.jpg){#fig-hal_botuse}

* 外在幻觉（Extrinsic Hallucinations）：生成了与源信息无关的内容。外在幻觉可能与事实冲突，也可能不冲突。在有些场景下，事实正确的外在幻觉可能会更好，但是事情往往并非总是如此。
    ![外在幻觉的例子](./images/bj_autumn.jpg){#fig-bj_autumn}

:::{.callout-important}
幻觉，大模型的阿克琉斯之踵。
:::

更多关于幻觉的详细内容可以参见：[-@NLPHallucination]，[-@LLMHallucination]。